/*
 * Copyright (C) 2022 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.android.server.wm.flicker.service

import android.app.Instrumentation
import android.device.collectors.BaseMetricListener
import android.device.collectors.DataRecord
import android.util.Log
import androidx.test.platform.app.InstrumentationRegistry
import com.android.server.wm.flicker.service.assertors.AssertionResult
import java.nio.file.Path
import org.junit.runner.Description
import org.junit.runner.Result
import org.junit.runner.notification.Failure

/**
 * Collects all the Flicker Service's metrics which are then uploaded for analysis and monitoring
 * to the CrystalBall database.
 */
class FlickerServiceResultsCollector(
    val outputDir: Path,
    private val tracesCollector: ITracesCollector = FlickerServiceTracesCollector(outputDir),
    instrumentation: Instrumentation = InstrumentationRegistry.getInstrumentation()
) : BaseMetricListener() {
    private var criticalUserJourneyName: String = UNDEFINED_CUJ
    private var collectMetricsPerTest = true

    // The flicker service results (aka metrics) we want to upload
    private val metrics = mutableMapOf<String, Int>()

    private val _executionErrors = mutableListOf<Throwable>()
    val executionErrors: List<Throwable> get() = _executionErrors

    init {
        setInstrumentation(instrumentation)
    }

    private fun errorReportingBlock(function: () -> Unit) {
        try {
            function()
        } catch (e: Throwable) {
            _executionErrors.add(e)
        }
    }

    override fun onTestRunStart(runData: DataRecord, description: Description) {
        errorReportingBlock {
            Log.i(LOG_TAG, "onTestRunStart :: collectMetricsPerTest = $collectMetricsPerTest")
            if (!collectMetricsPerTest) {
                require(metrics.isEmpty())
                tracesCollector.start()
            }
        }
    }

    override fun onTestStart(testData: DataRecord, description: Description) {
        errorReportingBlock {
            Log.i(LOG_TAG, "onTestStart :: collectMetricsPerTest = $collectMetricsPerTest")
            require(metrics.isEmpty())
            if (collectMetricsPerTest) {
                tracesCollector.start()
            }
        }
    }

    override fun onTestFail(testData: DataRecord, description: Description, failure: Failure) {
        errorReportingBlock {
            Log.i(LOG_TAG, "onTestFail")
        }
    }

    override fun onTestEnd(testData: DataRecord, description: Description) {
        errorReportingBlock {
            Log.i(LOG_TAG, "onTestEnd :: collectMetricsPerTest = $collectMetricsPerTest")
            if (collectMetricsPerTest) {
                stopTracingAndCollectFlickerMetrics(testData)
            }
        }
    }

    override fun onTestRunEnd(runData: DataRecord, result: Result) {
        errorReportingBlock {
            Log.i(LOG_TAG, "onTestRunEnd :: collectMetricsPerTest = $collectMetricsPerTest")
            if (!collectMetricsPerTest) {
                stopTracingAndCollectFlickerMetrics(runData)
                collectMetrics(runData)
            }
        }
    }

    fun postFlickerResultsForCollection(results: Map<String, Int>) {
        for ((key, res) in results) {
            require(res == 1 || res == 0)
            // If a failure is posted for key then we fail
            metrics[key] = (metrics[key] ?: 1) and res
        }
    }

    private fun stopTracingAndCollectFlickerMetrics(dataRecord: DataRecord) {
        tracesCollector.stop()
        val collectedTraces = tracesCollector.getCollectedTraces()
        val flickerService = FlickerService()
        val results = flickerService.process(
            collectedTraces.wmTrace,
            collectedTraces.layersTrace, collectedTraces.transitionsTrace
        )
        processFlickerResults(results)
        collectMetrics(dataRecord)
    }

    private fun collectMetrics(data: DataRecord) {
        val it = metrics.entries.iterator()
        while (it.hasNext()) {
            val (key, value) = it.next()
            data.addStringMetric(key, value.toString())
            it.remove()
        }
    }

    /**
     * Convert the assertions generated by the Flicker Service to specific metric key pairs that
     * contain enough information to later further and analyze in dashboards.
     */
    private fun processFlickerResults(results: List<AssertionResult>) {
        for (result in results) {
            // 0 for pass, 1 for failure
            val metric = if (result.failed) 1 else 0

            // Add information about the CUJ we are running the assertions on
            val assertionName = "${result.assertionGroup}#${result.assertionName}"
            val key = "$FASS_METRICS_PREFIX::$criticalUserJourneyName::$assertionName"
            if (metrics.containsKey(key)) {
                Log.w(LOG_TAG, "overriding metric $key")
            }
            metrics[key] = metric
        }
    }

    fun setCriticalUserJourneyName(className: String?) {
        this.criticalUserJourneyName = className ?: UNDEFINED_CUJ
    }

    companion object {
        // Unique prefix to add to all fass metrics to identify them
        private const val FASS_METRICS_PREFIX = "FASS"
        private const val UNDEFINED_CUJ = "UndefinedCUJ"
        private val LOG_TAG = "FlickerResultsCollector"
    }
}
